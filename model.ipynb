{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gym-trading-env pandas numpy matplotlib stable_baselines3 'shimmy>=0.2.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_trading_env\n",
    "\n",
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from stable_baselines3 import DQN,A2C,PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/NIFTY50 .csv')\n",
    "df['DatetimeIndex'] = pd.to_datetime(df['DatetimeIndex'])\n",
    "df.set_index('DatetimeIndex', inplace=True)\n",
    "df[\"feature_pct_change\"] = df[\"close\"].pct_change()\n",
    "df[\"feature_high\"] = df[\"high\"] / df[\"close\"] - 1\n",
    "df[\"feature_low\"] = df[\"low\"] / df[\"close\"] - 1\n",
    "df.dropna(inplace= True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make('TradingEnv',df=df,verbose=1,name='NIFTY50',trading_fees = 0.01/100,borrow_interest_rate= 0.0003/100,windows=5)\n",
    "done, truncated = False, False\n",
    "observation, info = env.reset()\n",
    "while not done and not truncated:\n",
    "    # Pick a position by its index in your position list (=[-1, 0, 1])....usually something like : position_index = your_policy(observation)\n",
    "    position_index = env.action_space.sample() # At every timestep, pick a random position index from your position list (=[-1, 0, 1])\n",
    "    observation, reward, done, truncated, info = env.step(position_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_maker():\n",
    "    return gym.make('TradingEnv',df=df,verbose=1,name='NIFTY50',trading_fees = 0.01/100,borrow_interest_rate= 0.0003/100)\n",
    "\n",
    "# Create the environment using make_vec_env\n",
    "env = DummyVecEnv([env_maker])\n",
    "\n",
    "\n",
    "# Train the PPO model\n",
    "model1 = PPO('MlpPolicy', env, verbose=1)\n",
    "model1.learn(total_timesteps=1000)\n",
    "# Train the A2C model\n",
    "model2 = A2C('MlpPolicy', env, verbose=1)\n",
    "model2.learn(total_timesteps=1000)\n",
    "# Train the DQN model\n",
    "model3 = DQN('MlpPolicy', env, verbose=1)\n",
    "model3.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('Data/test_data.csv')\n",
    "df_test['DatetimeIndex'] = pd.to_datetime(df_test['DatetimeIndex'])\n",
    "df_test.set_index('DatetimeIndex', inplace=True)\n",
    "df_test[\"feature_pct_change\"] = df_test[\"close\"].pct_change()\n",
    "df_test[\"feature_high\"] = df_test[\"high\"] / df_test[\"close\"] - 1\n",
    "df_test[\"feature_low\"] = df_test[\"low\"] / df_test[\"close\"] - 1\n",
    "df_test.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env=gym.make('TradingEnv',df=df_test,verbose=1,name='NIFTY50',trading_fees = 0.01/100,borrow_interest_rate= 0.0003/100)\n",
    "state,_=test_env.reset()\n",
    "truncated=0\n",
    "terminated=0\n",
    "while True:     \n",
    "    action,_states=model1.predict(state)\n",
    "    n_state,reward,truncated,terminated,info=test_env.step(action)\n",
    "    if truncated or terminated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env=gym.make('TradingEnv',df=df_test,verbose=1,name='NIFTY50',trading_fees = 0.01/100,borrow_interest_rate= 0.0003/100)\n",
    "state,_=test_env.reset()\n",
    "truncated=0\n",
    "terminated=0\n",
    "while True:     \n",
    "    action,_states=model2.predict(state)\n",
    "    n_state,reward,truncated,terminated,info=test_env.step(action)\n",
    "    if truncated or terminated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env=gym.make('TradingEnv',df=df_test,verbose=1,name='NIFTY50',trading_fees = 0.01/100,borrow_interest_rate= 0.0003/100)\n",
    "state,_=test_env.reset()\n",
    "truncated=0\n",
    "terminated=0\n",
    "while True:     \n",
    "    action,_states=model3.predict(state)\n",
    "    n_state,reward,truncated,terminated,info=test_env.step(action)\n",
    "    if truncated or terminated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the results above we conclude that the PPO & DQN model is best and hence we will be using that only for our predictions in all later models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym-trading-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
